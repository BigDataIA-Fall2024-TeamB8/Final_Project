{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c977dd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\sathu\\anaconda3\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: chromedriver-py in c:\\users\\sathu\\anaconda3\\lib\\site-packages (131.0.6778.85)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sathu\\anaconda3\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\sathu\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\sathu\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sathu\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium chromedriver-py tqdm pandas requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113bb8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TEDx talks scraping...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379bc4b9450b41d09b3d15404ec55095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 116\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved data to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Run Scraper\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m scrape_talks()\n\u001b[0;32m    117\u001b[0m talks \u001b[38;5;241m=\u001b[39m parse_talks()\n\u001b[0;32m    118\u001b[0m transcripts \u001b[38;5;241m=\u001b[39m scrape_transcripts(talks)\n",
      "Cell \u001b[1;32mIn[2], line 71\u001b[0m, in \u001b[0;36mscrape_talks\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://zenith-prod-alt.ted.com/api/search\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     64\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     json\u001b[38;5;241m=\u001b[39mpayload,\n\u001b[0;32m     69\u001b[0m )\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m---> 71\u001b[0m     talks \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     72\u001b[0m     final\u001b[38;5;241m.\u001b[39mextend(talks)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "from selenium.webdriver.remote.remote_connection import LOGGER\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from chromedriver_py import binary_path\n",
    "import requests\n",
    "\n",
    "# Reduce log verbosity\n",
    "LOGGER.setLevel(logging.WARNING)\n",
    "\n",
    "# Browser Setup\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument(\"window-size=1900,800\")\n",
    "chrome_options.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    ")\n",
    "\n",
    "def get_browser():\n",
    "    service = Service(executable_path=binary_path)\n",
    "    wd = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    return wd\n",
    "\n",
    "# Initialize browser\n",
    "browser = get_browser()\n",
    "\n",
    "# Scraper Configuration\n",
    "max_page = 300  # Set to -1 for unlimited pages\n",
    "sleep_time = 1\n",
    "final = []\n",
    "\n",
    "# Function to scrape TEDx talks\n",
    "def scrape_talks():\n",
    "    print(\"Starting TEDx talks scraping...\")\n",
    "    for page in tqdm(range(0, max_page)):\n",
    "        payload = [\n",
    "            {\n",
    "                \"indexName\": \"newest\",\n",
    "                \"params\": {\n",
    "                    \"attributeForDistinct\": \"objectID\",\n",
    "                    \"distinct\": 1,\n",
    "                    \"facets\": [\"subtitle_languages\", \"tags\"],\n",
    "                    \"highlightPostTag\": \"__/ais-highlight__\",\n",
    "                    \"highlightPreTag\": \"__ais-highlight__\",\n",
    "                    \"hitsPerPage\": 24,\n",
    "                    \"maxValuesPerFacet\": 500,\n",
    "                    \"page\": page,\n",
    "                    \"query\": \"\",\n",
    "                    \"tagFilters\": \"\"\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "        try:\n",
    "            r = requests.post(\n",
    "                'https://zenith-prod-alt.ted.com/api/search',\n",
    "                headers={\n",
    "                    'Content-type': 'application/json; charset=UTF-8',\n",
    "                    \"User-Agent\": \"curl/7.64.1\",\n",
    "                },\n",
    "                json=payload,\n",
    "            )\n",
    "            print(f\"Page {page} - Status Code: {r.status_code}\")\n",
    "            if r.status_code == 200 and r.headers.get('Content-Type') == 'application/json':\n",
    "                data = r.json()\n",
    "                talks = data.get('results', [{}])[0].get(\"hits\", [])\n",
    "                final.extend(talks)\n",
    "            else:\n",
    "                print(f\"Unexpected response on page {page}: {r.text}\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Request failed on page {page}: {e}\")\n",
    "        except JSONDecodeError as e:\n",
    "            print(f\"JSON decode error on page {page}: {e}\")\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "# Parse talk details\n",
    "def parse_talks():\n",
    "    final_list = []\n",
    "    for talk in final:\n",
    "        slug = talk[\"slug\"]\n",
    "        final_list.append(\n",
    "            {\n",
    "                'id': talk[\"objectID\"],\n",
    "                'slug': talk[\"slug\"],\n",
    "                'speakers': talk[\"speakers\"],\n",
    "                'title': talk[\"title\"],\n",
    "                \"url\": f'https://www.ted.com/talks/{slug}',\n",
    "            }\n",
    "        )\n",
    "    return final_list\n",
    "\n",
    "# Scrape transcript for each talk\n",
    "def scrape_transcripts(talks_list):\n",
    "    transcripts = []\n",
    "    for talk in tqdm(talks_list):\n",
    "        url = talk[\"url\"] + \"/transcript\"\n",
    "        try:\n",
    "            browser.get(url)\n",
    "            time.sleep(sleep_time)\n",
    "            transcript_elements = browser.find_elements(By.CLASS_NAME, \"Grid__cell\")\n",
    "            transcript = \" \".join([elem.text for elem in transcript_elements])\n",
    "            talk[\"transcript\"] = transcript\n",
    "            transcripts.append(talk)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch transcript for {talk['url']}: {e}\")\n",
    "    return transcripts\n",
    "\n",
    "# Save data to CSV\n",
    "def save_to_csv(data, filename):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved data to {filename}\")\n",
    "\n",
    "# Run Scraper\n",
    "scrape_talks()\n",
    "talks = parse_talks()\n",
    "transcripts = scrape_transcripts(talks)\n",
    "\n",
    "# Save results\n",
    "save_to_csv(talks, \"tedx_talks.csv\")\n",
    "save_to_csv(transcripts, \"tedx_transcripts.csv\")\n",
    "\n",
    "# Close the browser\n",
    "browser.quit()\n",
    "print(\"TEDx Scraping Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657124b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
